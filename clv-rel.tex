\section{Related Work}
\label{sec:rel}
The merits of applying fusion to document lists retrieved for queries
representing the same information need is now well
understood~\cite{Belkin+al:93a,Belkin+al:95a,Pickens+al:08a,bailey2017retrieval,bc17-adcs,Benham+al:19a}.
Our first retrieval template proposed uses cluster-based retrieval to
re-rank a list fused from the documents retrieved for a set of
queries representing the same information need.
We also explore the merits of applying fusion after each of the lists
retrieved for the queries was re-ranked using cluster-based
retrieval.
Benham and Culpepper \cite{bc17-adcs} showed that reciprocal rank
fusion \cite{Cormack+al:09a} consistently yields state-of-the-art
performance when fusing document lists retrieved for multiple queries
representing the same information need.
Our best performing methods substantially outperform this fusion
approach.
\shane{We should be a little careful here as someone will almost
certainly point out that this is the best unsupervised method.
We have never done it, but supervised techniques almost certainly
perform better such as LambdaMerge which we never got to work
properly.
We could add the numbers in the table from the best performing TREC
run for the Robust collection.
We cannot do that for CW12.}

Recent work on query performance prediction showed that the relative
prediction quality posted by prediction methods can significantly
vary when varying the effectiveness of a query used to represent an
information need \cite{Zendel+al:19a}.
In a conceptually similar vein, we show that state-of-the-art
cluster-based document retrieval methods can actually be outperformed
by standard bag-of-words document retrieval models if highly
effective queries are used to represent information needs.

To address the efficiency costs of using multiple queries, Benham et
al.~\cite{Benham+al:19a} proposed a highly effective reranking
technique which clusters queries offline.
At query time, the results retrieved for the (single) query input
into the search engine were fused with a centroid of the cluster with
which the query was associated.
The best query cluster to use for reranking is easily identified at
runtime using an auxiliary index of previously seen queries.
This work focuses on clustering document at query time, in contrast
to clustering queries at query time..

Previous work on cluster-based fusion of retrieved lists used the
documents in retrieval lists along with multiple ranking models for a
{\em single query} to induce cluster~\cite{Kozorovitzky+Kurland:11b}.
\shane{Did I get this right?
Sorry the initial text was a little unclear.}
Then, a cluster-based retrieval approach was applied using these
clusters to perform the fusion.
This fusion approach can be derived as a specific instantiation of
one of the retrieval templates we present for retrieval using {\em
multiple queries}.
While the performance of this adaptation is in fact highly effective,
we show that the performance can be further improved in this work.

